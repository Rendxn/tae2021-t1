---
title: "ModeloKNN"
output: html_document
bibliography: bibliography.bib
csl: ieee-with-url.csl
---

# Modelo de regresión utilizando KNN

El método de KNN, aunque utilizado generalmente para problemas de clasificación, puede ser también usado para casos de regresión. KNN utiliza las características de sus K vecinos más cercanos para hacer una predicción.

## Importe de librería para el modelo de regresión
```{r, warning=FALSE, message=FALSE}
# Caret para el modelo
library(caret)
# Para entrenar el modelo con multithreading
library(parallel)
library(doParallel)
library(kableExtra)
```

## Muestreo y separación en entrenamiento y validación

Se fija la semilla generadora de números aleatorios para garantizar la reproducibilidad de los resultados.

Adicionalmente, se separa el marco de datos en datos de entrenamiento y datos de validación o prueba. La proporción utilizada fue de $0.8$ para entrenamiento y $0.2$ para validación.

```{r}
# Semilla para generación de números aleatorios
set.seed(20210406)
# Asignación de índices del dataset para training 0.8 y testing 0.2 
indexTraining <- createDataPartition(y = clean_labeled_input$HIJOS, p = 0.8, list = FALSE)
# Parte del dataset designada para training
train <- clean_labeled_input[indexTraining,]
# Parte del dataset designada para testing
test <- clean_labeled_input[-indexTraining,]
```

## Preprocesamiento

Adicional al preprocesamiento realizado anteriormente para la obtención del conjunto de datos inicial, se realiza un pre-procesamiento específico al modelo KNN. Debido a que KNN es muy sensible a la distancia entre los datos y las unidades de estos, es necesario normalizar los datos antes de entrenar el modelo. El paquete `caret` hace este paso de normalización por nosotros, como una de las opciones a la hora de entrenar el modelo.

Debido a que se tiene una cantidad significativa de datos $(93.993)$, se decide no hacer imputación de datos, y en cambio, omitir los valores que contengan información incompleta.

## Entrenamiento y control

Se realiza el entrenamiento del modelo KNN, utilizando validación cruzada con 10 folds. Se prueban 5 modelos con diferentes valores de K, para ver cuál es el mejor valor de K. A esto se le conoce como **hyperparameter tuning**. Cada fold separa una parte aleatoria de los datos para entrenamiento y otra para validación de cada modelo.
```{r, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}
# Habilitar cluster para trabajo en paralelo
cluster <- makeCluster(detectCores() - 2) # habilitar n - 2 threads de la cpu
registerDoParallel(cluster)
# none: sin resampling ni validación cruzada
ctrl <- trainControl(method="cv", number = 10, allowParallel = TRUE)
# modelo
knn_fit <- train(HIJOS ~., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 5, na.action = na.omit)
# detener procesamiento en paralelo
stopCluster(cluster)
```
```{r, eval=FALSE}
# Guardamos el modelo
saveRDS(knn_fit, '../shiny/data/knnModel.rds')
```

```{r, message=FALSE, warning=FALSE, echo=FALSE}
knn_fit <- readRDS('../shiny/data/knnModel.rds')
```


Veamos qué valor de K obtuvo mejores resultados.

```{r}
# veamos cuál valor de K fue seleccionado como el mejor
knitr::kable(knn_fit$results) %>% kable_paper()
```

Según la optimización de parámetros, el mejor modelo es aquel con un valor de $K = 7$, pues obtuvo el menor RMSE y el mejor puntaje R2.

```{r}
# Veamos solamente el modelo seleccionado
knitr::kable(knn_fit$results[2,]) %>% kable_paper()
```
## Validación y pruebas

Se utiliza el conjunto de prueba para comprobar la validez del modelo y se visualiza su desempeño con los valores RMSE y R2.
```{r}
# Probamos el modelo con el conjunto de prueba
test_pred <- predict(knn_fit, newdata = test, na.action = na.omit)
```
### Medidas de desempeño

Principalmente, se utilizaron dos métricas para evaluar el desempeño del modelo.

#### RMSE (Raíz del error cuadrático medio)

El RMSE del modelo para el conjunto de pruebas es el siguiente:
```{r}
test_clean <- na.omit(test)
rmseVal <- RMSE(pred = test_pred, obs = test_clean$HIJOS)
```
Este valor mide la cantidad de error que hay entre el valor predicho y el valor conocido.

#### Coeficiente R2

El Coeficiente R2 para el conjunto de pruebas es el siguiente:
```{r}
r2Val <- R2(pred = test_pred, obs = test_clean$HIJOS)
```

```{r}
metricas <- as.data.frame(cbind(rmseVal, r2Val))
colnames(metricas) <- c("RMSE", "Valor R2")
knitr::kable(metricas) %>% kable_paper()
```

Este coeficiente representa la proporción de varianza en los resultados que nuestro modelo es capaz de explicar y nos da información sobre qué tan bien se ajusta el modelo a los datos [@ref1].